{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab3-practice.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMNiFlaMy10lkoplxTW3ofY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TtttttH/MLAI/blob/main/Lab3_practice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHWXdHXp_9nK"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "spam_data = pd.read_csv('https://raw.githubusercontent.com/maalvarezl/MLAI/master/Labs/datasets/spambase.data', header=None)\n",
        "spam_names_list = pd.read_csv('https://raw.githubusercontent.com/maalvarezl/MLAI/master/Labs/datasets/spambase.data.names', header=None)\n",
        "number_names = np.shape(spam_names_list)[0]\n",
        "spam_names = ['None']*number_names\n",
        "for i in range(number_names):\n",
        "    local = spam_names_list[0][i]\n",
        "    colon_pos = local.find(':')\n",
        "    spam_names[i] = local[:colon_pos]\n",
        "spam_data.columns = spam_names\n",
        "X = spam_data.iloc[:, 0:57]\n",
        "y = spam_data.iloc[:, 57]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BNo0OK0TcA9_"
      },
      "source": [
        "#Use the whole dataset to build a decision tree classifier\n",
        "\n",
        "from sklearn import tree\n",
        "clf = tree.DecisionTreeClassifier(criterion='entropy', max_depth=3)\n",
        "clf = clf.fit(X, y)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "wwmGFhPBcS83",
        "outputId": "8f28a291-2653-4f9a-ce72-715fdf84ce4c"
      },
      "source": [
        "import graphviz\n",
        "\n",
        "#export the tree as a pdf file\n",
        "dot_data = tree.export_graphviz(clf, out_file=None)\n",
        "graph = graphviz.Source(dot_data)\n",
        "graph.render(\"spam\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'spam.pdf'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPLVRZZser7r"
      },
      "source": [
        "# render the graph inline\n",
        "dot_data = tree.export_graphviz(clf, out_file=None,\n",
        "                                feature_names=spam_names[0:57],\n",
        "                                class_names=['ham', 'spam'],\n",
        "                                filled=True, rounded=True,\n",
        "                                special_characters=True)\n",
        "graph = graphviz.Source(dot_data)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "id": "lUT7cKcwfyjT",
        "outputId": "3da67b02-f8c7-41f0-9a4c-22cec64c5b96"
      },
      "source": [
        "graph"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7f53ff9fbe50>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: Tree Pages: 1 -->\n<svg width=\"1090pt\" height=\"433pt\"\n viewBox=\"0.00 0.00 1090.00 433.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 429)\">\n<title>Tree</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-429 1086,-429 1086,4 -4,4\"/>\n<!-- 0 -->\n<g id=\"node1\" class=\"node\">\n<title>0</title>\n<path fill=\"#f6d3ba\" stroke=\"#000000\" d=\"M620.5,-425C620.5,-425 495.5,-425 495.5,-425 489.5,-425 483.5,-419 483.5,-413 483.5,-413 483.5,-354 483.5,-354 483.5,-348 489.5,-342 495.5,-342 495.5,-342 620.5,-342 620.5,-342 626.5,-342 632.5,-348 632.5,-354 632.5,-354 632.5,-413 632.5,-413 632.5,-419 626.5,-425 620.5,-425\"/>\n<text text-anchor=\"start\" x=\"493\" y=\"-409.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">char_freq_$ ≤ 0.056</text>\n<text text-anchor=\"start\" x=\"507\" y=\"-394.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.967</text>\n<text text-anchor=\"start\" x=\"506\" y=\"-379.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 4601</text>\n<text text-anchor=\"start\" x=\"491.5\" y=\"-364.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [2788, 1813]</text>\n<text text-anchor=\"start\" x=\"518.5\" y=\"-349.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = ham</text>\n</g>\n<!-- 1 -->\n<g id=\"node2\" class=\"node\">\n<title>1</title>\n<path fill=\"#eda876\" stroke=\"#000000\" d=\"M548,-306C548,-306 382,-306 382,-306 376,-306 370,-300 370,-294 370,-294 370,-235 370,-235 370,-229 376,-223 382,-223 382,-223 548,-223 548,-223 554,-223 560,-229 560,-235 560,-235 560,-294 560,-294 560,-300 554,-306 548,-306\"/>\n<text text-anchor=\"start\" x=\"378\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">word_freq_remove ≤ 0.055</text>\n<text text-anchor=\"start\" x=\"414\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.787</text>\n<text text-anchor=\"start\" x=\"413\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3471</text>\n<text text-anchor=\"start\" x=\"403\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [2655, 816]</text>\n<text text-anchor=\"start\" x=\"425.5\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = ham</text>\n</g>\n<!-- 0&#45;&gt;1 -->\n<g id=\"edge1\" class=\"edge\">\n<title>0&#45;&gt;1</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M525.4731,-341.8796C518.5049,-332.9633 511.0753,-323.4565 503.8944,-314.268\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"506.5812,-312.0221 497.6657,-306.2981 501.0657,-316.3326 506.5812,-312.0221\"/>\n<text text-anchor=\"middle\" x=\"494.6225\" y=\"-327.4122\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">True</text>\n</g>\n<!-- 8 -->\n<g id=\"node9\" class=\"node\">\n<title>8</title>\n<path fill=\"#53aae8\" stroke=\"#000000\" d=\"M734.5,-306C734.5,-306 617.5,-306 617.5,-306 611.5,-306 605.5,-300 605.5,-294 605.5,-294 605.5,-235 605.5,-235 605.5,-229 611.5,-223 617.5,-223 617.5,-223 734.5,-223 734.5,-223 740.5,-223 746.5,-229 746.5,-235 746.5,-235 746.5,-294 746.5,-294 746.5,-300 740.5,-306 734.5,-306\"/>\n<text text-anchor=\"start\" x=\"613.5\" y=\"-290.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">word_freq_hp ≤ 0.4</text>\n<text text-anchor=\"start\" x=\"625\" y=\"-275.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.523</text>\n<text text-anchor=\"start\" x=\"624\" y=\"-260.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1130</text>\n<text text-anchor=\"start\" x=\"618\" y=\"-245.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [133, 997]</text>\n<text text-anchor=\"start\" x=\"633\" y=\"-230.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = spam</text>\n</g>\n<!-- 0&#45;&gt;8 -->\n<g id=\"edge8\" class=\"edge\">\n<title>0&#45;&gt;8</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M599.2707,-341.8796C608.3799,-332.6931 618.1108,-322.8798 627.4776,-313.4336\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"629.9973,-315.8634 634.5532,-306.2981 625.0267,-310.9345 629.9973,-315.8634\"/>\n<text text-anchor=\"middle\" x=\"634.6587\" y=\"-327.5978\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">False</text>\n</g>\n<!-- 2 -->\n<g id=\"node3\" class=\"node\">\n<title>2</title>\n<path fill=\"#ea9a60\" stroke=\"#000000\" d=\"M283,-187C283,-187 165,-187 165,-187 159,-187 153,-181 153,-175 153,-175 153,-116 153,-116 153,-110 159,-104 165,-104 165,-104 283,-104 283,-104 289,-104 295,-110 295,-116 295,-116 295,-175 295,-175 295,-181 289,-187 283,-187\"/>\n<text text-anchor=\"start\" x=\"161\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">char_freq_! ≤ 0.191</text>\n<text text-anchor=\"start\" x=\"173\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.644</text>\n<text text-anchor=\"start\" x=\"172\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 3141</text>\n<text text-anchor=\"start\" x=\"162\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [2625, 516]</text>\n<text text-anchor=\"start\" x=\"184.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = ham</text>\n</g>\n<!-- 1&#45;&gt;2 -->\n<g id=\"edge2\" class=\"edge\">\n<title>1&#45;&gt;2</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M380.7099,-222.8796C355.9156,-210.6367 328.8665,-197.2805 304.3273,-185.1637\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"305.5714,-181.8746 295.0553,-180.5854 302.4721,-188.1511 305.5714,-181.8746\"/>\n</g>\n<!-- 5 -->\n<g id=\"node6\" class=\"node\">\n<title>5</title>\n<path fill=\"#4da7e8\" stroke=\"#000000\" d=\"M542.5,-187C542.5,-187 387.5,-187 387.5,-187 381.5,-187 375.5,-181 375.5,-175 375.5,-175 375.5,-116 375.5,-116 375.5,-110 381.5,-104 387.5,-104 387.5,-104 542.5,-104 542.5,-104 548.5,-104 554.5,-110 554.5,-116 554.5,-116 554.5,-175 554.5,-175 554.5,-181 548.5,-187 542.5,-187\"/>\n<text text-anchor=\"start\" x=\"383.5\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">word_freq_george ≤ 0.14</text>\n<text text-anchor=\"start\" x=\"414\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.439</text>\n<text text-anchor=\"start\" x=\"417\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 330</text>\n<text text-anchor=\"start\" x=\"411\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [30, 300]</text>\n<text text-anchor=\"start\" x=\"422\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = spam</text>\n</g>\n<!-- 1&#45;&gt;5 -->\n<g id=\"edge5\" class=\"edge\">\n<title>1&#45;&gt;5</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M465,-222.8796C465,-214.6838 465,-205.9891 465,-197.5013\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"468.5001,-197.298 465,-187.2981 461.5001,-197.2981 468.5001,-197.298\"/>\n</g>\n<!-- 3 -->\n<g id=\"node4\" class=\"node\">\n<title>3</title>\n<path fill=\"#e78c4b\" stroke=\"#000000\" d=\"M128,-68C128,-68 12,-68 12,-68 6,-68 0,-62 0,-56 0,-56 0,-12 0,-12 0,-6 6,0 12,0 12,0 128,0 128,0 134,0 140,-6 140,-12 140,-12 140,-56 140,-56 140,-62 134,-68 128,-68\"/>\n<text text-anchor=\"start\" x=\"19\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.412</text>\n<text text-anchor=\"start\" x=\"18\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 2524</text>\n<text text-anchor=\"start\" x=\"8\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [2315, 209]</text>\n<text text-anchor=\"start\" x=\"30.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = ham</text>\n</g>\n<!-- 2&#45;&gt;3 -->\n<g id=\"edge3\" class=\"edge\">\n<title>2&#45;&gt;3</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M166.6561,-103.9815C153.2006,-94.2394 138.8869,-83.8759 125.5133,-74.193\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"127.4763,-71.2933 117.3238,-68.2637 123.3711,-76.9632 127.4763,-71.2933\"/>\n</g>\n<!-- 4 -->\n<g id=\"node5\" class=\"node\">\n<title>4</title>\n<path fill=\"#fffefd\" stroke=\"#000000\" d=\"M278,-68C278,-68 170,-68 170,-68 164,-68 158,-62 158,-56 158,-56 158,-12 158,-12 158,-6 164,0 170,0 170,0 278,0 278,0 284,0 290,-6 290,-12 290,-12 290,-56 290,-56 290,-62 284,-68 278,-68\"/>\n<text text-anchor=\"start\" x=\"181.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 1.0</text>\n<text text-anchor=\"start\" x=\"176\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 617</text>\n<text text-anchor=\"start\" x=\"166\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [310, 307]</text>\n<text text-anchor=\"start\" x=\"184.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = ham</text>\n</g>\n<!-- 2&#45;&gt;4 -->\n<g id=\"edge4\" class=\"edge\">\n<title>2&#45;&gt;4</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M224,-103.9815C224,-95.618 224,-86.7965 224,-78.3409\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"227.5001,-78.2636 224,-68.2637 220.5001,-78.2637 227.5001,-78.2636\"/>\n</g>\n<!-- 6 -->\n<g id=\"node7\" class=\"node\">\n<title>6</title>\n<path fill=\"#44a3e6\" stroke=\"#000000\" d=\"M420,-68C420,-68 320,-68 320,-68 314,-68 308,-62 308,-56 308,-56 308,-12 308,-12 308,-6 314,0 320,0 320,0 420,0 420,0 426,0 432,-6 432,-12 432,-12 432,-56 432,-56 432,-62 426,-68 420,-68\"/>\n<text text-anchor=\"start\" x=\"319\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.302</text>\n<text text-anchor=\"start\" x=\"322\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 317</text>\n<text text-anchor=\"start\" x=\"316\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [17, 300]</text>\n<text text-anchor=\"start\" x=\"327\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = spam</text>\n</g>\n<!-- 5&#45;&gt;6 -->\n<g id=\"edge6\" class=\"edge\">\n<title>5&#45;&gt;6</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M429.6255,-103.9815C421.8732,-94.8828 413.6591,-85.242 405.8869,-76.1199\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"408.3428,-73.6056 399.1933,-68.2637 403.0146,-78.1454 408.3428,-73.6056\"/>\n</g>\n<!-- 7 -->\n<g id=\"node8\" class=\"node\">\n<title>7</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M545.5,-68C545.5,-68 462.5,-68 462.5,-68 456.5,-68 450.5,-62 450.5,-56 450.5,-56 450.5,-12 450.5,-12 450.5,-6 456.5,0 462.5,0 462.5,0 545.5,0 545.5,0 551.5,0 557.5,-6 557.5,-12 557.5,-12 557.5,-56 557.5,-56 557.5,-62 551.5,-68 545.5,-68\"/>\n<text text-anchor=\"start\" x=\"461.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"460\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 13</text>\n<text text-anchor=\"start\" x=\"458.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [13, 0]</text>\n<text text-anchor=\"start\" x=\"464.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = ham</text>\n</g>\n<!-- 5&#45;&gt;7 -->\n<g id=\"edge7\" class=\"edge\">\n<title>5&#45;&gt;7</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M479.5222,-103.9815C482.5118,-95.4342 485.6688,-86.4086 488.6854,-77.7839\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"492.0174,-78.8585 492.0154,-68.2637 485.41,-76.5473 492.0174,-78.8585\"/>\n</g>\n<!-- 9 -->\n<g id=\"node10\" class=\"node\">\n<title>9</title>\n<path fill=\"#47a4e7\" stroke=\"#000000\" d=\"M743,-187C743,-187 609,-187 609,-187 603,-187 597,-181 597,-175 597,-175 597,-116 597,-116 597,-110 603,-104 609,-104 609,-104 743,-104 743,-104 749,-104 755,-110 755,-116 755,-116 755,-175 755,-175 755,-181 749,-187 743,-187\"/>\n<text text-anchor=\"start\" x=\"605\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">word_freq_edu ≤ 0.49</text>\n<text text-anchor=\"start\" x=\"625\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.351</text>\n<text text-anchor=\"start\" x=\"624\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1060</text>\n<text text-anchor=\"start\" x=\"622\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [70, 990]</text>\n<text text-anchor=\"start\" x=\"633\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = spam</text>\n</g>\n<!-- 8&#45;&gt;9 -->\n<g id=\"edge9\" class=\"edge\">\n<title>8&#45;&gt;9</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M676,-222.8796C676,-214.6838 676,-205.9891 676,-197.5013\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"679.5001,-197.298 676,-187.2981 672.5001,-197.2981 679.5001,-197.298\"/>\n</g>\n<!-- 12 -->\n<g id=\"node13\" class=\"node\">\n<title>12</title>\n<path fill=\"#e88f4f\" stroke=\"#000000\" d=\"M979,-187C979,-187 827,-187 827,-187 821,-187 815,-181 815,-175 815,-175 815,-116 815,-116 815,-110 821,-104 827,-104 827,-104 979,-104 979,-104 985,-104 991,-110 991,-116 991,-116 991,-175 991,-175 991,-181 985,-187 979,-187\"/>\n<text text-anchor=\"start\" x=\"823\" y=\"-171.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">word_freq_email ≤ 0.285</text>\n<text text-anchor=\"start\" x=\"852\" y=\"-156.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.469</text>\n<text text-anchor=\"start\" x=\"859\" y=\"-141.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 70</text>\n<text text-anchor=\"start\" x=\"857.5\" y=\"-126.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [63, 7]</text>\n<text text-anchor=\"start\" x=\"863.5\" y=\"-111.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = ham</text>\n</g>\n<!-- 8&#45;&gt;12 -->\n<g id=\"edge12\" class=\"edge\">\n<title>8&#45;&gt;12</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M746.5799,-227.5C768.1806,-216.1763 792.2136,-203.5775 814.8322,-191.7201\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"816.5241,-194.785 823.7558,-187.0421 813.274,-188.5853 816.5241,-194.785\"/>\n</g>\n<!-- 10 -->\n<g id=\"node11\" class=\"node\">\n<title>10</title>\n<path fill=\"#44a2e6\" stroke=\"#000000\" d=\"M688,-68C688,-68 588,-68 588,-68 582,-68 576,-62 576,-56 576,-56 576,-12 576,-12 576,-6 582,0 588,0 588,0 688,0 688,0 694,0 700,-6 700,-12 700,-12 700,-56 700,-56 700,-62 694,-68 688,-68\"/>\n<text text-anchor=\"start\" x=\"587\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.297</text>\n<text text-anchor=\"start\" x=\"586\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 1045</text>\n<text text-anchor=\"start\" x=\"584\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [55, 990]</text>\n<text text-anchor=\"start\" x=\"595\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = spam</text>\n</g>\n<!-- 9&#45;&gt;10 -->\n<g id=\"edge10\" class=\"edge\">\n<title>9&#45;&gt;10</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M661.8502,-103.9815C658.9372,-95.4342 655.8612,-86.4086 652.9219,-77.7839\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"656.2161,-76.6 649.6773,-68.2637 649.5904,-78.8582 656.2161,-76.6\"/>\n</g>\n<!-- 11 -->\n<g id=\"node12\" class=\"node\">\n<title>11</title>\n<path fill=\"#e58139\" stroke=\"#000000\" d=\"M813.5,-68C813.5,-68 730.5,-68 730.5,-68 724.5,-68 718.5,-62 718.5,-56 718.5,-56 718.5,-12 718.5,-12 718.5,-6 724.5,0 730.5,0 730.5,0 813.5,0 813.5,0 819.5,0 825.5,-6 825.5,-12 825.5,-12 825.5,-56 825.5,-56 825.5,-62 819.5,-68 813.5,-68\"/>\n<text text-anchor=\"start\" x=\"729.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"728\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 15</text>\n<text text-anchor=\"start\" x=\"726.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [15, 0]</text>\n<text text-anchor=\"start\" x=\"732.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = ham</text>\n</g>\n<!-- 9&#45;&gt;11 -->\n<g id=\"edge11\" class=\"edge\">\n<title>9&#45;&gt;11</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M711.7469,-103.9815C719.6599,-94.7908 728.0491,-85.0472 735.9732,-75.8436\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"738.6271,-78.1255 742.4994,-68.2637 733.3224,-73.5582 738.6271,-78.1255\"/>\n</g>\n<!-- 13 -->\n<g id=\"node14\" class=\"node\">\n<title>13</title>\n<path fill=\"#e5833c\" stroke=\"#000000\" d=\"M950,-68C950,-68 856,-68 856,-68 850,-68 844,-62 844,-56 844,-56 844,-12 844,-12 844,-6 850,0 856,0 856,0 950,0 950,0 956,0 962,-6 962,-12 962,-12 962,-56 962,-56 962,-62 956,-68 950,-68\"/>\n<text text-anchor=\"start\" x=\"852\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.116</text>\n<text text-anchor=\"start\" x=\"859\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 64</text>\n<text text-anchor=\"start\" x=\"857.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [63, 1]</text>\n<text text-anchor=\"start\" x=\"863.5\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = ham</text>\n</g>\n<!-- 12&#45;&gt;13 -->\n<g id=\"edge13\" class=\"edge\">\n<title>12&#45;&gt;13</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M903,-103.9815C903,-95.618 903,-86.7965 903,-78.3409\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"906.5001,-78.2636 903,-68.2637 899.5001,-78.2637 906.5001,-78.2636\"/>\n</g>\n<!-- 14 -->\n<g id=\"node15\" class=\"node\">\n<title>14</title>\n<path fill=\"#399de5\" stroke=\"#000000\" d=\"M1070,-68C1070,-68 992,-68 992,-68 986,-68 980,-62 980,-56 980,-56 980,-12 980,-12 980,-6 986,0 992,0 992,0 1070,0 1070,0 1076,0 1082,-6 1082,-12 1082,-12 1082,-56 1082,-56 1082,-62 1076,-68 1070,-68\"/>\n<text text-anchor=\"start\" x=\"988.5\" y=\"-52.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">entropy = 0.0</text>\n<text text-anchor=\"start\" x=\"991.5\" y=\"-37.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">samples = 6</text>\n<text text-anchor=\"start\" x=\"989.5\" y=\"-22.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">value = [0, 6]</text>\n<text text-anchor=\"start\" x=\"988\" y=\"-7.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\" fill=\"#000000\">class = spam</text>\n</g>\n<!-- 12&#45;&gt;14 -->\n<g id=\"edge14\" class=\"edge\">\n<title>12&#45;&gt;14</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M950.6625,-103.9815C961.5297,-94.5151 973.0705,-84.462 983.9135,-75.0168\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"986.4245,-77.4712 991.6659,-68.2637 981.8266,-72.1929 986.4245,-77.4712\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxfSuZGYyMe1"
      },
      "source": [
        "#the hyparameters: the criterion or impurity measure(criterion)\n",
        "#split the train_set and the test_set by crossvalidating\n",
        "from sklearn.model_selection import ShuffleSplit\n",
        "ss = ShuffleSplit(n_splits=2, test_size=0.3, random_state=42)\n",
        "indexes = list(ss.split(X, y))\n",
        "train_set = indexes[0][0]\n",
        "test_set = indexes[0][1]\n",
        "Xtrain = X.iloc[train_set, :]\n",
        "ytrain = y.iloc[train_set]\n",
        "Xtest = X.iloc[test_set, :]\n",
        "ytest = y.iloc[test_set]"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "NaS24T6d14NT",
        "outputId": "34cf8edb-be0f-4d61-daa6-6a01eace7699"
      },
      "source": [
        "Xtrain"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word_freq_make</th>\n",
              "      <th>word_freq_address</th>\n",
              "      <th>word_freq_all</th>\n",
              "      <th>word_freq_3d</th>\n",
              "      <th>word_freq_our</th>\n",
              "      <th>word_freq_over</th>\n",
              "      <th>word_freq_remove</th>\n",
              "      <th>word_freq_internet</th>\n",
              "      <th>word_freq_order</th>\n",
              "      <th>word_freq_mail</th>\n",
              "      <th>word_freq_receive</th>\n",
              "      <th>word_freq_will</th>\n",
              "      <th>word_freq_people</th>\n",
              "      <th>word_freq_report</th>\n",
              "      <th>word_freq_addresses</th>\n",
              "      <th>word_freq_free</th>\n",
              "      <th>word_freq_business</th>\n",
              "      <th>word_freq_email</th>\n",
              "      <th>word_freq_you</th>\n",
              "      <th>word_freq_credit</th>\n",
              "      <th>word_freq_your</th>\n",
              "      <th>word_freq_font</th>\n",
              "      <th>word_freq_000</th>\n",
              "      <th>word_freq_money</th>\n",
              "      <th>word_freq_hp</th>\n",
              "      <th>word_freq_hpl</th>\n",
              "      <th>word_freq_george</th>\n",
              "      <th>word_freq_650</th>\n",
              "      <th>word_freq_lab</th>\n",
              "      <th>word_freq_labs</th>\n",
              "      <th>word_freq_telnet</th>\n",
              "      <th>word_freq_857</th>\n",
              "      <th>word_freq_data</th>\n",
              "      <th>word_freq_415</th>\n",
              "      <th>word_freq_85</th>\n",
              "      <th>word_freq_technology</th>\n",
              "      <th>word_freq_1999</th>\n",
              "      <th>word_freq_parts</th>\n",
              "      <th>word_freq_pm</th>\n",
              "      <th>word_freq_direct</th>\n",
              "      <th>word_freq_cs</th>\n",
              "      <th>word_freq_meeting</th>\n",
              "      <th>word_freq_original</th>\n",
              "      <th>word_freq_project</th>\n",
              "      <th>word_freq_re</th>\n",
              "      <th>word_freq_edu</th>\n",
              "      <th>word_freq_table</th>\n",
              "      <th>word_freq_conference</th>\n",
              "      <th>char_freq_;</th>\n",
              "      <th>char_freq_(</th>\n",
              "      <th>char_freq_[</th>\n",
              "      <th>char_freq_!</th>\n",
              "      <th>char_freq_$</th>\n",
              "      <th>char_freq_#</th>\n",
              "      <th>capital_run_length_average</th>\n",
              "      <th>capital_run_length_longest</th>\n",
              "      <th>capital_run_length_total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>958</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.21</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.21</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.21</td>\n",
              "      <td>1.21</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.21</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>4.87</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.676</td>\n",
              "      <td>15</td>\n",
              "      <td>57</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1533</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.33</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.208</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.417</td>\n",
              "      <td>0.208</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.812</td>\n",
              "      <td>16</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>654</th>\n",
              "      <td>0.33</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.33</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.99</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.66</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.116</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.406</td>\n",
              "      <td>0.464</td>\n",
              "      <td>0.348</td>\n",
              "      <td>6.932</td>\n",
              "      <td>43</td>\n",
              "      <td>513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1497</th>\n",
              "      <td>0.52</td>\n",
              "      <td>1.31</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.90</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.26</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.79</td>\n",
              "      <td>1.05</td>\n",
              "      <td>1.58</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.31</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.79</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.138</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.046</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>2.934</td>\n",
              "      <td>60</td>\n",
              "      <td>135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3844</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>15.38</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>14.000</td>\n",
              "      <td>53</td>\n",
              "      <td>56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4426</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.55</td>\n",
              "      <td>0.27</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.122</td>\n",
              "      <td>0.081</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.040</td>\n",
              "      <td>3.891</td>\n",
              "      <td>70</td>\n",
              "      <td>323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>466</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.95</td>\n",
              "      <td>2.61</td>\n",
              "      <td>1.66</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.61</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>3.80</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.95</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.47</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.121</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.040</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.780</td>\n",
              "      <td>55</td>\n",
              "      <td>189</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3092</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.49</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.49</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.47</td>\n",
              "      <td>2.98</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.49</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.49</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.49</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.229</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>2.333</td>\n",
              "      <td>10</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3772</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.15</td>\n",
              "      <td>0.92</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.23</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.063</td>\n",
              "      <td>0.063</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.159</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.616</td>\n",
              "      <td>13</td>\n",
              "      <td>173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>860</th>\n",
              "      <td>0.10</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.41</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.52</td>\n",
              "      <td>0.1</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.62</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.20</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.10</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.73</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.048</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.016</td>\n",
              "      <td>0.064</td>\n",
              "      <td>0.000</td>\n",
              "      <td>1.915</td>\n",
              "      <td>29</td>\n",
              "      <td>339</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3220 rows × 57 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      word_freq_make  ...  capital_run_length_total\n",
              "958             0.00  ...                        57\n",
              "1533            0.00  ...                        61\n",
              "654             0.33  ...                       513\n",
              "1497            0.52  ...                       135\n",
              "3844            0.00  ...                        56\n",
              "...              ...  ...                       ...\n",
              "4426            0.00  ...                       323\n",
              "466             0.00  ...                       189\n",
              "3092            0.00  ...                        49\n",
              "3772            0.00  ...                       173\n",
              "860             0.10  ...                       339\n",
              "\n",
              "[3220 rows x 57 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1ZEZO5-3aNu",
        "outputId": "869017f7-8cde-464a-d912-7da9e5ed2def"
      },
      "source": [
        "#Create a Grid search for the parameters criterion\n",
        "# and max_depth and we use the training data to find the best parameters\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "criterion_opts = np.array(['entropy', 'gini'])\n",
        "max_depth_opts = [3, 5, 10, 15]\n",
        "param_grid = dict(criterion = criterion_opts, max_depth = max_depth_opts)\n",
        "cv = ShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
        "grid = GridSearchCV(tree.DecisionTreeClassifier(), param_grid=param_grid, cv=cv, scoring='accuracy')\n",
        "grid.fit(Xtrain, ytrain)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=ShuffleSplit(n_splits=1, random_state=42, test_size=0.3, train_size=None),\n",
              "             error_score=nan,\n",
              "             estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features=None,\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              presort='deprecated',\n",
              "                                              random_state=None,\n",
              "                                              splitter='best'),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'criterion': array(['entropy', 'gini'], dtype='<U7'),\n",
              "                         'max_depth': [3, 5, 10, 15]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-swVN-a94hFw",
        "outputId": "a879ed29-2a7b-4e0f-83f4-8c243e8ff869"
      },
      "source": [
        "grid.best_params_"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'criterion': 'gini', 'max_depth': 15}"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BSUGxQ8OQLy2"
      },
      "source": [
        "clf = tree.DecisionTreeClassifier(criterion=grid.best_params_[\"criterion\"],max_depth=grid.best_params_[\"max_depth\"])\n",
        "clf.fit(Xtrain, ytrain)\n",
        "ypred = clf.predict(Xtest)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yx7oN68UUbW",
        "outputId": "e3fda1f2-d8be-4d24-9354-e8b2b7ed9958"
      },
      "source": [
        "#evaluate the accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "accuracy = accuracy_score(ytest, ypred)\n",
        "print(accuracy)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9109341057204924\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "OTfLO9ILU1J3",
        "outputId": "741f0e0b-8f2b-4825-cc77-b3a457371df4"
      },
      "source": [
        "#distribution of the labels\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "y.hist()\n",
        "plt.ylabel('Number of instances')\n",
        "plt.xlabel('Class label')\n",
        "plt.title('Class distribution for X')\n",
        "plt.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "aV6xFs-QmOYq",
        "outputId": "dfc1403b-e3b0-4ef1-bbb0-d9f0058d6854"
      },
      "source": [
        "ytrain.hist()\n",
        "plt.ylabel('Number of instances')\n",
        "plt.xlabel('Class label')\n",
        "plt.title('Class distribution for Xtrain')\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itz_1LS_nSHs"
      },
      "source": [
        "Notice that the numbers of data observations per class are different. We usually refer to this kind of problems as \"imbalanced\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "nYr3OvjGnQxV",
        "outputId": "a2714b7f-04d1-46c7-9c00-fa84e8a4f168"
      },
      "source": [
        "from imblearn.under_sampling import ClusterCentroids\n",
        "import numpy as np\n",
        "cc = ClusterCentroids(random_state=0)\n",
        "X_resampled, y_resampled = cc.fit_resample(Xtrain, ytrain)\n",
        "# Cluster centroids uses the kMeans algorithm to select a representative subset \n",
        "# of examples from the majority class, you can read more about it in the docs\n",
        "# for the imblearn module. \n",
        "#recheck whether X_resampled, y_resampled are a balanced dataset\n",
        "plt.hist(y_resampled)\n",
        "plt.ylabel('Number of instances')\n",
        "plt.xlabel('Class label')\n",
        "plt.title('Class distribution for X_resampled')\n",
        "plt.show()"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zqQJeiEIr_rJ",
        "outputId": "4b5fc30c-5017-4231-a986-1733e21e555b"
      },
      "source": [
        "# The resampled dataset now has same number of samples in both classes\n",
        "# choose best parameters\n",
        "criterion_opts_q1 = np.array(['entropy', 'gini'])\n",
        "max_depth_opts_q1 = [3, 5, 10, 15]\n",
        "param_grid_q1 = dict(criterion = criterion_opts_q1, max_depth = max_depth_opts_q1)\n",
        "cv_q1 = ShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
        "grid_q1 = GridSearchCV(tree.DecisionTreeClassifier(), param_grid=param_grid_q1,cv=cv_q1, scoring='accuracy')\n",
        "grid_q1.fit(X_resampled, y_resampled)\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=ShuffleSplit(n_splits=1, random_state=42, test_size=0.3, train_size=None),\n",
              "             error_score=nan,\n",
              "             estimator=DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None,\n",
              "                                              criterion='gini', max_depth=None,\n",
              "                                              max_features=None,\n",
              "                                              max_leaf_nodes=None,\n",
              "                                              min_impurity_decrease=0.0,\n",
              "                                              min_impurity_split=None,\n",
              "                                              min_samples_leaf=1,\n",
              "                                              min_samples_split=2,\n",
              "                                              min_weight_fraction_leaf=0.0,\n",
              "                                              presort='deprecated',\n",
              "                                              random_state=None,\n",
              "                                              splitter='best'),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'criterion': array(['entropy', 'gini'], dtype='<U7'),\n",
              "                         'max_depth': [3, 5, 10, 15]},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring='accuracy', verbose=0)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XW3NNxqpvse_",
        "outputId": "8e572498-c3d3-4745-8f97-bb73c184eded"
      },
      "source": [
        "grid.best_params_"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'criterion': 'gini', 'max_depth': 15}"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2qFVJ8rv0pX",
        "outputId": "d2cea037-ee68-44ad-a93a-dcc85bc961b7"
      },
      "source": [
        "clf_q1 = tree.DecisionTreeClassifier(criterion='gini', max_depth=15)\n",
        "clf_q1.fit(X_resampled, y_resampled)\n",
        "ypred_q1 = clf_q1.predict(Xtest)\n",
        "\n",
        "#check the accuracy\n",
        "accuracy_q1 = accuracy_score(ytest, ypred_q1)\n",
        "accuracy_q1"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9080376538740044"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-LtVXaOlwi94",
        "outputId": "d67ecee2-a9e3-4f42-8398-b19cbe787ee8"
      },
      "source": [
        "#Using a performance measure:\n",
        "from sklearn.metrics import classification_report\n",
        "print('The performance for model in q1 in resampled dataset:')\n",
        "print(classification_report(ytest,ypred_q1))\n",
        "from sklearn.metrics import recall_score\n",
        "print('The recall for model in q1 in resampled dataset:')\n",
        "print(recall_score(ytest, ypred_q1))\n",
        "print('The recall for model in original dataset:')\n",
        "print(recall_score(ytest, ypred))"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The performance for model in q1 in resampled dataset:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.92      0.92       804\n",
            "           1       0.89      0.89      0.89       577\n",
            "\n",
            "    accuracy                           0.91      1381\n",
            "   macro avg       0.91      0.91      0.91      1381\n",
            "weighted avg       0.91      0.91      0.91      1381\n",
            "\n",
            "The recall for model in q1 in resampled dataset:\n",
            "0.8925476603119584\n",
            "The recall for model in original dataset:\n",
            "0.878682842287695\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTl_wz0_0UlD"
      },
      "source": [
        "##Decision trees for regression\n",
        "import urllib.request\n",
        "import pandas as pd\n",
        "urllib.request.urlretrieve('https://archive.ics.uci.edu/ml/machine-learning-databases/00560/SeoulBikeData.csv', './SeoulBikeData.csv')\n",
        "bike_sharing_data = pd.read_csv('SeoulBikeData.csv', encoding= 'unicode_escape')\n",
        "bike_sharing_data = bike_sharing_data.drop('Date', axis=1)\n",
        "# We transform the int64 variables in the dataset to float64.\n",
        "for col in ['Rented Bike Count', 'Hour', 'Humidity(%)', 'Visibility (10m)']:\n",
        "    bike_sharing_data[col] = bike_sharing_data[col].astype('float64')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wOzxoyP-KEJ"
      },
      "source": [
        "for col in ['Rented Bike Count', 'Hour', 'Humidity(%)', 'Visibility (10m)']:\n",
        "  bike_sharing_data[col] = bike_sharing_data[col].astype('float64')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8ivPL3D-J_8"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "bs_train_set, bs_test_set = train_test_split(bike_sharing_data, test_size=0.15, random_state=42)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I-rWk9dr-4Ux"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "attributes_cat = ['Seasons', 'Holiday', 'Functioning Day']\n",
        "attributes_num = ['Hour', 'Temperature(°C)', 'Humidity(%)', 'Wind speed (m/s)', 'Visibility (10m)', \\\n",
        "                  'Dew point temperature(°C)', 'Solar Radiation (MJ/m2)', 'Rainfall(mm)', 'Snowfall (cm)']   \n",
        "\n",
        "full_transform = ColumnTransformer([\n",
        "    (\"num\", StandardScaler(), attributes_num),\n",
        "    (\"cat\", OneHotEncoder(), attributes_cat),\n",
        "])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhVVoPp2_Lmo"
      },
      "source": [
        "bs_train2_set, bs_val_set = train_test_split(bs_train_set, test_size=0.15,random_state=42)\n",
        "bs_train2_set_attributes = bs_train2_set.drop('Rented Bike Count', axis=1)\n",
        "bs_train2_set_labels = bs_train2_set['Rented Bike Count']\n",
        "bs_val_set_attributes = bs_val_set.drop('Rented Bike Count', axis=1)\n",
        "bs_val_set_labels = bs_val_set['Rented Bike Count']"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCq_ULpY_8XO"
      },
      "source": [
        "# fit transform in the train set\n",
        "bs_train2_set_attributes_transformed = full_transform.fit_transform(bs_train2_set_attributes)\n",
        "# transform in the validation set\n",
        "bs_val_set_attributes_transformed = full_transform.transform(bs_val_set_attributes)\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgV3SAdJAXJ9"
      },
      "source": [
        "#Since we want to perform a GridSearchCV on the same validation data that we used for Lab2\n",
        "#we will use preDefinedSplit to tell the cross validator which instances to use for training\n",
        "#and which ones for validation.\n",
        "#We create first a test_fold array of the same dimensionality than the original training data\n",
        "#and assign the value of -1 to the indexes corresponding to train instances and 0 to the indexes\n",
        "#corresponding to validation instances. We will then stack the input attributes for both sets and also stack the labels."
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGOERIGgCI7P"
      },
      "source": [
        "from sklearn.model_selection import PredefinedSplit\n",
        "import numpy as np\n",
        "test_fold = np.zeros((np.shape(bs_train_set)[0], 1))\n",
        "#train instances\n",
        "test_fold[0:np.shape(bs_train2_set)[0]] = -1\n",
        "#validation instances\n",
        "ps = PredefinedSplit(test_fold)\n",
        "\n",
        "whole_train_set_attributes = np.vstack((bs_train2_set_attributes_transformed, bs_val_set_attributes_transformed))\n",
        "whole_train_set_labels = np.hstack((bs_train2_set_labels, bs_val_set_labels))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SOxhHdjirlZm"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRPElkWWu4Qd",
        "outputId": "d1c16fb1-1c7d-49e1-8d8d-64a45c34610d"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import tree\n",
        "max_depth_opts = [3, 5, 10, 15]\n",
        "param_grid = dict(max_depth = max_depth_opts)\n",
        "#neg_mean_squared_error is used to envaluate the scoring for regression tree\n",
        "grid_regression = GridSearchCV(tree.DecisionTreeRegressor(), param_grid=param_grid, cv=ps, scoring='neg_mean_squared_error')\n",
        "grid_regression.fit(whole_train_set_attributes, whole_train_set_labels)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
              "             error_score=nan,\n",
              "             estimator=DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse',\n",
              "                                             max_depth=None, max_features=None,\n",
              "                                             max_leaf_nodes=None,\n",
              "                                             min_impurity_decrease=0.0,\n",
              "                                             min_impurity_split=None,\n",
              "                                             min_samples_leaf=1,\n",
              "                                             min_samples_split=2,\n",
              "                                             min_weight_fraction_leaf=0.0,\n",
              "                                             presort='deprecated',\n",
              "                                             random_state=None,\n",
              "                                             splitter='best'),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'max_depth': [3, 5, 10, 15]}, pre_dispatch='2*n_jobs',\n",
              "             refit=True, return_train_score=False,\n",
              "             scoring='neg_mean_squared_error', verbose=0)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUoPiRI0rqWg",
        "outputId": "2b802e79-e195-4658-9faa-a4fb711a74c3"
      },
      "source": [
        "grid_regression.best_params_"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_depth': 10}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEadU2WUyEA-"
      },
      "source": [
        "regr = tree.DecisionTreeRegressor(max_depth=10)\n",
        "regr.fit(bs_train2_set_attributes_transformed, bs_train2_set_labels)\n",
        "bs_val_set_predictions = regr.predict(bs_val_set_attributes_transformed)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tz9YbyPFytCJ",
        "outputId": "d86bec3d-024b-43a7-aee6-b052a5c757e3"
      },
      "source": [
        "#Compute the RMSE for the validation dataset\n",
        "from sklearn.metrics import mean_squared_error\n",
        "error_mod = np.sqrt(mean_squared_error(bs_val_set_labels, bs_val_set_predictions))\n",
        "error_mod"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "274.586692496466"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDmUVp2ezNzh"
      },
      "source": [
        "Question 2\n",
        "Decision trees do not require any scaling of the features.Use the same splits of the data than before but use the numerical features as they come, this is , **do not use StandardScaler()** for the **numerical features**.What is the RMSE on the validation data?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SRPtUC4OzMZr"
      },
      "source": [
        "q2_transform = ColumnTransformer([\n",
        "    (\"cat\", OneHotEncoder(), attributes_cat),\n",
        "], remainder = 'passthrough')"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRIKsbfc0HOU"
      },
      "source": [
        "bs_train2_set_attributes_q2_transformed = q2_transform.fit_transform(bs_train2_set_attributes)\n",
        "\n",
        "bs_val_set_attributes_q2_transformed = q2_transform.transform(bs_val_set_attributes)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_o_8P1JH1k6u"
      },
      "source": [
        "from sklearn.model_selection import PredefinedSplit\n",
        "test_fold_q2 = np.zeros((np.shape(bs_train_set)[0], 1))\n",
        "test_fold[0:np.shape(bs_train2_set)[0]] = -1\n",
        "ps = PredefinedSplit(test_fold)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5prNYCZW18_2"
      },
      "source": [
        "whole_train_set_attributes_q2 = np.vstack((bs_train2_set_attributes_q2_transformed, bs_val_set_attributes_q2_transformed))\n",
        "whole_train_set_labels_q2 = np.hstack((bs_train2_set_labels, bs_val_set_labels))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJzVAsJW2R2r",
        "outputId": "cbc4e0de-5385-4371-f712-c98b8b4819ec"
      },
      "source": [
        "max_depth_opts = [3, 5, 10, 15]\n",
        "param_grid_q2 = dict(max_depth = max_depth_opts)\n",
        "#Exhaustive search over specified parameter values for an estimator.\n",
        "grid_regression_q2 = GridSearchCV(tree.DecisionTreeRegressor(), param_grid=param_grid_q2, cv=ps, scoring='neg_mean_squared_error')\n",
        "grid_regression_q2.fit(whole_train_set_attributes_q2, whole_train_set_labels_q2)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=PredefinedSplit(test_fold=array([-1, -1, ...,  0,  0])),\n",
              "             error_score=nan,\n",
              "             estimator=DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse',\n",
              "                                             max_depth=None, max_features=None,\n",
              "                                             max_leaf_nodes=None,\n",
              "                                             min_impurity_decrease=0.0,\n",
              "                                             min_impurity_split=None,\n",
              "                                             min_samples_leaf=1,\n",
              "                                             min_samples_split=2,\n",
              "                                             min_weight_fraction_leaf=0.0,\n",
              "                                             presort='deprecated',\n",
              "                                             random_state=None,\n",
              "                                             splitter='best'),\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'max_depth': [3, 5, 10, 15]}, pre_dispatch='2*n_jobs',\n",
              "             refit=True, return_train_score=False,\n",
              "             scoring='neg_mean_squared_error', verbose=0)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1QrWVyq2yRj",
        "outputId": "1ec60af9-52c6-458f-c6d0-a73a8cb5949e"
      },
      "source": [
        "grid_regression_q2.best_params_"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_depth': 10}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGEuPRSG22gr"
      },
      "source": [
        "regr_q2 = tree.DecisionTreeRegressor(max_depth=grid_regression.best_params_[\"max_depth\"], random_state=42)\n",
        "regr_q2.fit(bs_train2_set_attributes_q2_transformed, bs_train2_set_labels)\n",
        "bs_val_set_predictions_q2 = regr_q2.predict(bs_val_set_attributes_q2_transformed)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuAn4hP13sUE",
        "outputId": "97c68db2-2d88-41c0-80ba-0a32ddc52bc3"
      },
      "source": [
        "#Compute the RMSE for the validation dataset\n",
        "error_mod = np.sqrt(mean_squared_error(bs_val_set_labels, bs_val_set_predictions_q2))\n",
        "error_mod"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "281.28636247641964"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2rpWLVFOB3e",
        "outputId": "55191184-32ca-4a15-d90c-05fac13d0256"
      },
      "source": [
        "#Random Forests\n",
        "#Some parameters:\n",
        "#1. n_estimators : total number of trees to train\n",
        "#2. max_features : number of features to use as candidates for splitting at each tree node\n",
        "#3. bootstrape: whether bootstrap samples are used when building trees. if False, the whole dataset is used to build each tree.(means that whether the samples can be repeated used)\n",
        "#4. max_samples:If bootstrap is True, the number of samples to draw from X to train each base estimator. \n",
        "\n",
        "#Question 3\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "q3_transform = ColumnTransformer([\n",
        "    (\"cat\", OneHotEncoder(),attributes_cat),\n",
        "], remainder='passthrough')\n",
        "\n",
        "##fit transform on the train set\n",
        "bs_train2_set_attributes_q3 = q3_transform.fit_transform(bs_train2_set_attributes)\n",
        "##transform the validation set\n",
        "bs_val_set_attributes_q3 = q3_transform.transform(bs_val_set_attributes)\n",
        "\n",
        "whole_train_set_attributes_q3 = np.vstack((bs_train2_set_attributes_q3,bs_val_set_attributes_q3))\n",
        "whole_train_set_labels_q3 = np.hstack((bs_train2_set_labels, bs_val_set_labels))\n",
        "\n",
        "##Applying the Random Forest for regression and exploring different maximum depth options\n",
        "#set those values for the parameters n_estimators and max_samples.\n",
        "n_estimators_q3 = [20, 50, 100, 200]\n",
        "max_samples_q3 = [500, 1000, 2000, 3000]\n",
        "param_grid_q3 = dict(n_estimators = n_estimators_q3, max_samples = max_samples_q3)\n",
        "grid_regression_q3 = GridSearchCV(RandomForestRegressor(), param_grid=param_grid_q3, cv=ps, scoring='neg_mean_squared_error')\n",
        "#remember to fit the train dataset\n",
        "grid_regression_q3.fit(whole_train_set_attributes_q3, whole_train_set_labels_q3)\n",
        "##Training a RF using the best value for the n_estimators and max_samples\n",
        "regr_Q3 = RandomForestRegressor(n_estimators = grid_regression_q3.best_params_[\"n_estimators\"], max_samples=grid_regression_q3.best_params_[\"max_samples\"])\n",
        "regr_Q3.fit(bs_train2_set_attributes_q3, bs_train2_set_labels)\n",
        "bs_val_set_predictions = regr_Q3.predict(bs_val_set_attributes_q3)\n",
        "\n",
        "##compute the RSME for bs_val_set\n",
        "from sklearn.metrics import mean_squared_error\n",
        "error_q3 = np.sqrt(mean_squared_error(bs_val_set_predictions, bs_val_set_labels))\n",
        "error_q3\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "231.12955905262388"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sYvm1P8XZgLI",
        "outputId": "4b88d12e-1af7-42f7-b8c2-b8b6fdf5a4e8"
      },
      "source": [
        "grid_regression_q3.best_params_"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'max_samples': 3000, 'n_estimators': 50}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WaOVZzHOcX6_"
      },
      "source": [
        "# Gradient Boosting\n",
        "In Gradient Boosting or Gradient-boosted trees,each treein the ensemble is trained sequentially"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0vifad3-qgBx",
        "outputId": "c2c8dd7d-0b79-4b33-8fa9-48590407406e"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "q2_transform = ColumnTransformer([\n",
        "                                  (\"cat\", OneHotEncoder(), attributes_cat),\n",
        "],remainder='passthrough')\n",
        "\n",
        "bs_train2_set_attributes_q4 = q2_transform.fit_transform(bs_train2_set_attributes)\n",
        "bs_val_set_attributes_q4 = q2_transform.transform(bs_val_set_attributes)\n",
        "\n",
        "whole_train_set_attributes_q4 = np.vstack((bs_train2_set_attributes_q4, bs_val_set_attributes_q4))\n",
        "whole_train_set_labels_q4 = np.hstack((bs_train2_set_labels, bs_val_set_labels))\n",
        "\n",
        "n_estimators_Q4 = [50, 100, 200, 500]\n",
        "max_features_Q4 = [3, 5, 10, 15]\n",
        "param_grid_q4 = dict(n_estimators = n_estimators_Q4, max_features = max_features_Q4)\n",
        "grid_regression_q4 = GridSearchCV(GradientBoostingRegressor(), param_grid=param_grid_q4, cv=ps, scoring='neg_mean_squared_error')\n",
        "grid_regression_q4.fit(whole_train_set_attributes_q4, whole_train_set_labels_q4)\n",
        "\n",
        "regr_q4 = GradientBoostingRegressor(n_estimators = grid_regression_q4.best_params_[\"n_estimators\"], max_features = grid_regression_q4.best_params_[\"max_features\"])\n",
        "regr_q4.fit(bs_train2_set_attributes_q4, bs_train2_set_labels)\n",
        "\n",
        "bs_val_set_predictions_q4 = regr_q4.predict(bs_val_set_attributes_q4)\n",
        "error_q4 = np.sqrt(mean_squared_error(bs_val_set_predictions, bs_val_set_labels))\n",
        "print('The RMSE on the validation data is:', error_q4)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The RMSE on the validation data is: 231.12955905262388\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gCPRqIOr5mj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}